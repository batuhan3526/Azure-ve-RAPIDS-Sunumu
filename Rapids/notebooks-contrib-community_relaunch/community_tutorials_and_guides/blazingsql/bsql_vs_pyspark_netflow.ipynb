{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d0hJ4z8rBOFC"
   },
   "source": [
    "# BlazingSQL vs. Apache Spark \n",
    "\n",
    "Below we have one of our popular workloads running with [BlazingSQL](https://blazingsql.com/) + [RAPIDS AI](https://rapids.ai) and then running the entire ETL phase again, only this time with Apache Spark + PySpark.\n",
    "\n",
    "In this notebook, we will cover: \n",
    "- How to read and query csv files with cuDF and BlazingSQL.\n",
    "- How BlazingSQL compares against Apache Spark (analyzing over 20M records)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BlazingSQL install check\n",
    "The next cell checks to determine if you have BlazingSQL installed.  If you do not have BlazingSQL installed, please first install RAPIDS and BlazingSQL via your preferred installation method (Docker or conda) from our [Release Selector](https://rapids.ai/start.html#rapids-release-selector). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You've got BlazingSQL set up perfectly! Let's get started with SQL in RAPIDS AI!\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys \n",
    "# point import path notebooks-contrib/utils\n",
    "sys.path.append('../../utils') \n",
    "from sql_check import bsql_start\n",
    "# check that BlazingSQL is installed\n",
    "bsql_start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Data\n",
    "This cell will check if you have the data for this demo, and, if you don't, will download it for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You've got the data!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# relative path to data folder\n",
    "data_dir = '../../data/blazingsql/'\n",
    "# file name\n",
    "fn = 'nf-chunk2.csv'\n",
    "\n",
    "# does folder exist?\n",
    "if not os.path.exists(data_dir):\n",
    "    print('creating blazingsql directory')\n",
    "    # create folder\n",
    "    os.system('mkdir ../../data/blazingsql')\n",
    "\n",
    "# do we have music file?\n",
    "if not os.path.isfile(data_dir + fn):\n",
    "    # save nf-chunk2 to data folder, may take a few minutes to download (21,526,138 records)\n",
    "    !wget -P ../../data/blazingsql https://blazingsql-colab.s3.amazonaws.com/netflow_data/nf-chunk2.csv\n",
    "else:\n",
    "    print(\"You've got the data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create BlazingContext\n",
    "You can think of the BlazingContext much like a Spark Context, this is where information such as FileSystems you have registered and Tables you have created will be stored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ojm_V-WAtz0f",
    "outputId": "a46625f4-1494-4a13-eb13-2f38efd80ccf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BlazingContext ready\n"
     ]
    }
   ],
   "source": [
    "import cudf\n",
    "from blazingsql import BlazingContext\n",
    "# start up BlazingSQL\n",
    "bc = BlazingContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OTEaAsp2_zmf"
   },
   "source": [
    "## BlazingSQL + cuDF \n",
    "Data in hand, we can test the preformance of cuDF and BlazingSQL on this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "rirBsYQU3NH5",
    "outputId": "51ced2b1-b930-4173-bbfa-09672e751d3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.63 s, sys: 236 ms, total: 1.87 s\n",
      "Wall time: 1.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load CSVs into GPU DataFrames (GDF)\n",
    "netflow_gdf = cudf.read_csv(data_dir + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "zCzLEFfB3N4k",
    "outputId": "10ff9097-2736-423e-969d-de75983fbdda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.36 s, sys: 43.5 ms, total: 1.4 s\n",
      "Wall time: 545 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create BlazingSQL table from GDF - There is no copy in this process\n",
    "bc.create_table('netflow', netflow_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "umBG2Tp0wbQx",
    "outputId": "0975395e-7f5b-4244-afa3-45c8658ce61c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 567 ms, sys: 52.4 ms, total: 619 ms\n",
      "Wall time: 290 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# define the query\n",
    "query = '''\n",
    "        select\n",
    "            a.firstSeenSrcIp as source,\n",
    "            a.firstSeenDestIp as destination,\n",
    "            count(a.firstSeenDestPort) as targetPorts,\n",
    "            sum(a.firstSeenSrcTotalBytes) as bytesOut,\n",
    "            sum(a.firstSeenDestTotalBytes) as bytesIn,\n",
    "            sum(a.durationSeconds) as durationSeconds,\n",
    "            min(parsedDate) as firstFlowDate,\n",
    "            max(parsedDate) as lastFlowDate,\n",
    "            count(*) as attemptCount\n",
    "        from \n",
    "            netflow a\n",
    "        group by\n",
    "            a.firstSeenSrcIp,\n",
    "            a.firstSeenDestIp\n",
    "            '''\n",
    "\n",
    "# query the table (returns cudf dataframe)\n",
    "result_gdf = bc.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "48_W2v8q_zmq",
    "outputId": "db0394f1-e082-49b0-c477-e3bba8d3d0f4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>targetPorts</th>\n",
       "      <th>bytesOut</th>\n",
       "      <th>bytesIn</th>\n",
       "      <th>durationSeconds</th>\n",
       "      <th>firstFlowDate</th>\n",
       "      <th>lastFlowDate</th>\n",
       "      <th>attemptCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>172.10.1.33</td>\n",
       "      <td>10.0.0.11</td>\n",
       "      <td>110</td>\n",
       "      <td>49886</td>\n",
       "      <td>69630</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-04-03 06:51:58</td>\n",
       "      <td>2013-04-03 14:45:47</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172.30.1.126</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>9</td>\n",
       "      <td>2275</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2013-04-03 06:35:52</td>\n",
       "      <td>2013-04-03 12:05:31</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>172.30.2.133</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>5</td>\n",
       "      <td>1225</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2013-04-03 06:36:08</td>\n",
       "      <td>2013-04-03 06:36:15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>172.30.1.149</td>\n",
       "      <td>10.0.0.9</td>\n",
       "      <td>78</td>\n",
       "      <td>35309</td>\n",
       "      <td>48556</td>\n",
       "      <td>30</td>\n",
       "      <td>2013-04-03 06:48:27</td>\n",
       "      <td>2013-04-03 11:52:55</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0.0.13</td>\n",
       "      <td>172.10.1.81</td>\n",
       "      <td>1</td>\n",
       "      <td>633</td>\n",
       "      <td>392</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-04-03 09:48:26</td>\n",
       "      <td>2013-04-03 09:48:26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>172.10.0.5</td>\n",
       "      <td>10.247.58.129</td>\n",
       "      <td>3</td>\n",
       "      <td>1617</td>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-04-03 10:16:11</td>\n",
       "      <td>2013-04-03 11:37:15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.0.0.14</td>\n",
       "      <td>172.10.2.143</td>\n",
       "      <td>1</td>\n",
       "      <td>571</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-04-03 10:13:57</td>\n",
       "      <td>2013-04-03 10:13:57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>172.10.1.2</td>\n",
       "      <td>10.0.0.10</td>\n",
       "      <td>97</td>\n",
       "      <td>44092</td>\n",
       "      <td>61401</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-04-03 06:48:54</td>\n",
       "      <td>2013-04-03 15:05:37</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>172.10.1.212</td>\n",
       "      <td>10.0.0.9</td>\n",
       "      <td>102</td>\n",
       "      <td>46260</td>\n",
       "      <td>64410</td>\n",
       "      <td>23</td>\n",
       "      <td>2013-04-03 06:50:02</td>\n",
       "      <td>2013-04-03 14:31:50</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>172.30.1.160</td>\n",
       "      <td>10.0.0.12</td>\n",
       "      <td>65</td>\n",
       "      <td>29402</td>\n",
       "      <td>40520</td>\n",
       "      <td>16</td>\n",
       "      <td>2013-04-03 06:55:18</td>\n",
       "      <td>2013-04-03 11:52:13</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         source      destination  targetPorts  bytesOut  bytesIn  \\\n",
       "0   172.10.1.33        10.0.0.11          110     49886    69630   \n",
       "1  172.30.1.126  239.255.255.250            9      2275        0   \n",
       "2  172.30.2.133  239.255.255.250            5      1225        0   \n",
       "3  172.30.1.149         10.0.0.9           78     35309    48556   \n",
       "4     10.0.0.13      172.10.1.81            1       633      392   \n",
       "5    172.10.0.5    10.247.58.129            3      1617      108   \n",
       "6     10.0.0.14     172.10.2.143            1       571      108   \n",
       "7    172.10.1.2        10.0.0.10           97     44092    61401   \n",
       "8  172.10.1.212         10.0.0.9          102     46260    64410   \n",
       "9  172.30.1.160        10.0.0.12           65     29402    40520   \n",
       "\n",
       "   durationSeconds        firstFlowDate         lastFlowDate  attemptCount  \n",
       "0                0  2013-04-03 06:51:58  2013-04-03 14:45:47           110  \n",
       "1               12  2013-04-03 06:35:52  2013-04-03 12:05:31             9  \n",
       "2                6  2013-04-03 06:36:08  2013-04-03 06:36:15             5  \n",
       "3               30  2013-04-03 06:48:27  2013-04-03 11:52:55            78  \n",
       "4                0  2013-04-03 09:48:26  2013-04-03 09:48:26             1  \n",
       "5                4  2013-04-03 10:16:11  2013-04-03 11:37:15             3  \n",
       "6                0  2013-04-03 10:13:57  2013-04-03 10:13:57             1  \n",
       "7                2  2013-04-03 06:48:54  2013-04-03 15:05:37            97  \n",
       "8               23  2013-04-03 06:50:02  2013-04-03 14:31:50           102  \n",
       "9               16  2013-04-03 06:55:18  2013-04-03 11:52:13            65  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how's it look?\n",
    "result_gdf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6PXbjW1hTxrD"
   },
   "source": [
    "## Apache Spark\n",
    "The cell below installs Apache Spark ([PySpark](https://spark.apache.org/docs/latest/api/python/index.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pnEEvVEtT8xi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Using cached pyspark-3.1.1.tar.gz (212.3 MB)\n",
      "Collecting py4j==0.10.9\n",
      "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
      "\u001b[K     |████████████████████████████████| 198 kB 27.8 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=f924906e4f699df53b02459122288353d7e6790a0d5cb0181040406516c56b44\n",
      "  Stored in directory: /root/.cache/pip/wheels/43/47/42/bc413c760cf9d3f7b46ab7cd6590e8c47ebfd19a7386cd4a57\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9 pyspark-3.1.1\n"
     ]
    }
   ],
   "source": [
    "# installs Spark (2.4.4 Jan 2020)\n",
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W3-XmZkz_zmw"
   },
   "source": [
    "#### PyBlazing vs PySpark\n",
    "With everything installed we can launch a SparkSession and see how BlazingSQL stacks up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "nioEt2MqT9B0",
    "outputId": "f75b9823-5dbd-45b1-9282-562d3d6ddaf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.5 ms, sys: 39.9 ms, total: 79.4 ms\n",
      "Wall time: 6.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#I copied this cell's snippet from another Google Colab by Luca Canali here: https://colab.research.google.com/github/LucaCanali/sparkMeasure/blob/master/examples/SparkMeasure_Jupyter_Colab_Example.ipynb\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create Spark Session\n",
    "# This example uses a local cluster, you can modify master to use  YARN or K8S if available \n",
    "# This example downloads sparkMeasure 0.13 for scala 2_11 from maven central\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"PySpark Netflow Benchmark code\") \\\n",
    "        .config(\"spark.jars.packages\",\"ch.cern.sparkmeasure:spark-measure_2.11:0.13\")  \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G8XSppQiUdLY"
   },
   "source": [
    "### Load & Query Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ZSLuSYSOUDtf",
    "outputId": "2b93169b-63c5-4c46-da14-af87645bf51b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.5 ms, sys: 33.8 ms, total: 61.3 ms\n",
      "Wall time: 40 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load CSV into Spark\n",
    "netflow_df = spark.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load(data_dir+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "iT3BwLn8UDwE",
    "outputId": "4eeff800-489f-4230-adb9-f3a1c16ede66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.21 ms, sys: 283 µs, total: 1.49 ms\n",
      "Wall time: 155 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create table for querying\n",
    "netflow_df.createOrReplaceTempView('netflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "9SBhahA5UD2k",
    "outputId": "accc1938-6470-44df-ab7f-70058c755b2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+-----------+--------+-------+---------------+-------------------+-------------------+------------+\n",
      "|   source| destination|targetPorts|bytesOut|bytesIn|durationSeconds|      firstFlowDate|       lastFlowDate|attemptCount|\n",
      "+---------+------------+-----------+--------+-------+---------------+-------------------+-------------------+------------+\n",
      "|10.0.0.10| 172.20.1.73|          1|     571|    108|              0|2013-04-03 10:08:30|2013-04-03 10:08:30|           1|\n",
      "|10.0.0.10|172.30.1.221|          1|     633|    392|              0|2013-04-03 10:10:39|2013-04-03 10:10:39|           1|\n",
      "|10.0.0.10| 172.30.2.67|          1|     633|    392|              0|2013-04-03 10:43:48|2013-04-03 10:43:48|           1|\n",
      "|10.0.0.11| 172.20.1.55|          1|     571|    108|              0|2013-04-03 10:11:52|2013-04-03 10:11:52|           1|\n",
      "|10.0.0.11|172.30.1.245|          3|    1837|    892|              0|2013-04-03 09:45:12|2013-04-03 11:27:32|           3|\n",
      "+---------+------------+-----------+--------+-------+---------------+-------------------+-------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 33 ms, sys: 24.3 ms, total: 57.3 ms\n",
      "Wall time: 38.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# define the same query run tested on blazingsql above\n",
    "query = '''\n",
    "        SELECT\n",
    "            a.firstSeenSrcIp as source,\n",
    "            a.firstSeenDestIp as destination,\n",
    "            count(a.firstSeenDestPort) as targetPorts,\n",
    "            SUM(a.firstSeenSrcTotalBytes) as bytesOut,\n",
    "            SUM(a.firstSeenDestTotalBytes) as bytesIn,\n",
    "            SUM(a.durationSeconds) as durationSeconds,\n",
    "            MIN(parsedDate) as firstFlowDate,\n",
    "            MAX(parsedDate) as lastFlowDate,\n",
    "            COUNT(*) as attemptCount\n",
    "        FROM\n",
    "            netflow a\n",
    "        GROUP BY\n",
    "            a.firstSeenSrcIp,\n",
    "            a.firstSeenDestIp\n",
    "        '''\n",
    "\n",
    "# query with Spark\n",
    "edges_df = spark.sql(query)\n",
    "\n",
    "# set/display results\n",
    "edges_df.show(5)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "vs_pyspark_netflow.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
